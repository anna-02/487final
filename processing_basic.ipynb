{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt  # plotting\n",
    "import numpy as np  # linear algebra\n",
    "import os  # accessing directory structure\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "from typing import List\n",
    "from unicodedata import bidirectional\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nRowsRead = 2500  # specify 'None' if want to read whole file\n",
    "# train-balanced-sarcasm.csv has 1010826 rows in reality, but we are only loading/previewing the first 1000 rows\n",
    "sarc_data = pd.read_csv('train-balanced-sarcasm.csv',\n",
    "                  delimiter=',', nrows=nRowsRead)\n",
    "sarc_data .dataframeName = 'train-balanced-sarcasm.csv'\n",
    "nRow, nCol = sarc_data.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')\n",
    "print(sarc_data[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SARCDataset(Dataset):\n",
    "    \"\"\"Dataset for modified QA task on SQuAD2.0\"\"\"\n",
    "\n",
    "    def __init__(self, data: List[dict]):\n",
    "        super().__init__()\n",
    "        self.wv_data = KeyedVectors.load('drive/MyDrive/Assignment 4/glove.kv')\n",
    "        self.data = data\n",
    "\n",
    "        # getting unk val\n",
    "        # for key in self.wv_data:\n",
    "        arr = np.array([self.wv_data[i] for i in self.wv_data.index2word])\n",
    "        unk = np.mean(arr, axis=0)\n",
    "        dataset = []\n",
    "\n",
    "        for d in data:\n",
    "            # get questions\n",
    "            questions = []\n",
    "            for q in d['qas']:\n",
    "                ques = q['question']\n",
    "                ques = word_tokenize(ques)\n",
    "                q_rep = [0.0]*300\n",
    "                count = 0\n",
    "                for w in ques:\n",
    "                    if w in self.wv_data:\n",
    "                        q_rep += self.wv_data[w]\n",
    "                    else:\n",
    "                        q_rep += unk\n",
    "                    count += 1\n",
    "                q_rep = q_rep / count\n",
    "                questions.append(q_rep)\n",
    "\n",
    "            # get contexts\n",
    "            context = []\n",
    "            for c in d['context']:\n",
    "                #c = c.lower()\n",
    "                cont = word_tokenize(c)\n",
    "                c_rep = [0.0]*300\n",
    "                count = 0\n",
    "                for w in cont:\n",
    "                    if w in self.wv_data:\n",
    "                        c_rep += self.wv_data[w]\n",
    "                    else:\n",
    "                        c_rep += unk\n",
    "                    count += 1\n",
    "                c_rep = c_rep / count\n",
    "                context.append(c_rep)\n",
    "\n",
    "            # get labels\n",
    "            labels = []\n",
    "            for i in range(len(questions)):\n",
    "                labels.append([0.0]*len(context))\n",
    "                for j in range(len(context)):\n",
    "                    if d['qas'][i]['is_impossible'] == True:\n",
    "                        val = 0\n",
    "                    elif d['qas'][i]['answer']['sentence_id'] == j:\n",
    "                        val = 1\n",
    "                    else:\n",
    "                        val = 0\n",
    "                    val = np.float32(val)\n",
    "                    labels[i][j] = val\n",
    "\n",
    "            # get sentence ids\n",
    "            sentence_ids = []\n",
    "            for q in d['qas']:\n",
    "                if q['is_impossible']:\n",
    "                    sentence_ids.append(-1)\n",
    "                else:\n",
    "                    sentence_ids.append(q['answer']['sentence_id'])\n",
    "\n",
    "            dp = dict()\n",
    "            dp['questions'] = torch.tensor(np.array(questions))\n",
    "            dp['context'] = torch.tensor(np.array(context))\n",
    "            dp['labels'] = torch.tensor(np.array(labels))\n",
    "            dp['sentence_ids'] = torch.tensor(np.array(sentence_ids))\n",
    "\n",
    "            dataset.append(dp)\n",
    "\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "\n",
    "\n",
    "def basic_collate_fn(batch):\n",
    "    \"\"\"Collate function for basic setting.\"\"\"\n",
    "    # questions\n",
    "    questions = [i['questions'] for i in batch]\n",
    "    # context\n",
    "    context = [i['context'] for i in batch]\n",
    "    # labels\n",
    "    labels = [i['labels'].reshape(-1) for i in batch]\n",
    "    labels = torch.cat(labels)\n",
    "    # sentence ids\n",
    "    sent_ids = [i['sentence_ids'] for i in batch]\n",
    "    sent_ids = torch.cat(sent_ids)\n",
    "\n",
    "    return questions, context, labels, sent_ids\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6aaccf985712f3365a0665cd97e1d700c84dd895d6e91bdf4f720763f515c96a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('eecs487')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
