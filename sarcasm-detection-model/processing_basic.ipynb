{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt  # plotting\n",
    "import numpy as np  # linear algebra\n",
    "import os  # accessing directory structure\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "from typing import List\n",
    "from unicodedata import bidirectional\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "import csv\n",
    "from csv import reader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nRowsRead = 30000  # specify 'None' if want to read whole file\n",
    "# train-balanced-sarcasm.csv has 1010826 rows in reality, but we are only loading/previewing the first 1000 rows\n",
    "sarc_data = pd.read_csv('train-balanced-sarcasm.csv',\n",
    "                        delimiter=',', nrows=nRowsRead)\n",
    "sdf = sarc_data.loc[sarc_data['label']==1].head(n=3000)\n",
    "nsdf = sarc_data.loc[sarc_data['label'] == 0].head(n=3000)\n",
    "utrain = pd.concat([sdf[0:2200], nsdf[0:2200]])\n",
    "# udev = pd.concat([sdf[4000:4300], nsdf[6000:9000]])\n",
    "# \n",
    "\n",
    "# utrain = sarc_data.head(n=5000) #25000\n",
    "udev = sarc_data[15000:16400] #5000\n",
    "\n",
    "utrain_shuff = utrain.iloc[np.random.permutation(len(utrain))]\n",
    "utrain_shuff = utrain_shuff.reset_index(drop=True)\n",
    "utrain_shuff_copy = utrain_shuff[['label', 'comment', 'parent_comment']].copy()\n",
    "utrain_shuff_copy.to_csv('train.csv', index=False)\n",
    "\n",
    "udev_shuff = udev.iloc[np.random.permutation(len(udev))]\n",
    "udev_shuff = udev_shuff.reset_index(drop=True)\n",
    "udev_shuff_copy = udev_shuff[['label', 'comment', 'parent_comment']].copy()\n",
    "udev_shuff_copy.to_csv('dev.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6aaccf985712f3365a0665cd97e1d700c84dd895d6e91bdf4f720763f515c96a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('eecs487')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
